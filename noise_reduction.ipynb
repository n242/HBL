{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio cleaned and saved as: /media/faisal/RE_AS/REASEARCHASSISTANT/RECORDS/record1/1_STORY_BOTH_edited.wav\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import noisereduce as nr\n",
    "import numpy as np\n",
    "\n",
    "def clean_audio(input_path):\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_wav(input_path)\n",
    "    \n",
    "    # Convert to numpy array for noise reduction\n",
    "    audio_array = np.array(audio.get_array_of_samples())\n",
    "    \n",
    "    # Perform noise reduction\n",
    "    reduced_noise = nr.reduce_noise(y=audio_array, sr=audio.frame_rate)\n",
    "    \n",
    "    # Create a new AudioSegment object from the cleaned audio\n",
    "    cleaned_audio = AudioSegment(\n",
    "        reduced_noise.tobytes(),\n",
    "        frame_rate=audio.frame_rate,\n",
    "        sample_width=reduced_noise.dtype.itemsize,\n",
    "        channels=audio.channels\n",
    "    )\n",
    "    \n",
    "    # Export the cleaned audio to a new file\n",
    "    output_path = input_path[:-4] + \"_edited.wav\"\n",
    "    cleaned_audio.export(output_path, format=\"wav\")\n",
    "    \n",
    "    print(\"Audio cleaned and saved as:\", output_path)\n",
    "path = \"/media/faisal/RE_AS/REASEARCHASSISTANT/RECORDS/record1/1_STORY_BOTH.wav\"\n",
    "clean_audio(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "def convert_wav_to_mp3(input_path):\n",
    "    # Load the WAV file\n",
    "    audio = AudioSegment.from_wav(input_path)\n",
    "\n",
    "    # Remove the file extension from the input path\n",
    "    output_path = os.path.splitext(input_path)[0]\n",
    "\n",
    "    # Set the output path to have the .mp3 extension\n",
    "    output_path += \".mp3\"\n",
    "\n",
    "    # Export the audio as MP3\n",
    "    audio.export(output_path, format=\"mp3\")\n",
    "\n",
    "    print(\"WAV converted to MP3 and saved as:\", output_path)\n",
    "\n",
    "convert_wav_to_mp3(\"/media/faisal/RE_AS/REASEARCHASSISTANT/RECORDS/record1/1_EMOTIONS_BOTH.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in 222_STORY_BOTH.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MP4 converted to WAV: 222_STORY_BOTH.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "import os\n",
    "\n",
    "def convert_mp4_to_wav(input_path, output_path):\n",
    "    # Load the video clip\n",
    "    video = VideoFileClip(input_path)\n",
    "\n",
    "    # Extract the audio from the video clip\n",
    "    audio = video.audio\n",
    "\n",
    "    # Set the output file path\n",
    "    output_file = os.path.splitext(output_path)[0] + \".wav\"\n",
    "\n",
    "    # Write the audio to the output file\n",
    "    audio.write_audiofile(output_file, codec=\"pcm_s16le\", ffmpeg_params=[\"-ac\", \"1\"])\n",
    "\n",
    "    # Close the video and audio clips\n",
    "    video.close()\n",
    "    audio.close()\n",
    "\n",
    "    print(\"MP4 converted to WAV:\", output_file)\n",
    "\n",
    "input_path = \"/media/faisal/RE_AS/REASEARCHASSISTANT/RECORDS/record222/Done222/story_subject.mp4\"\n",
    "output_path = \"222_STORY_BOTH.wav\"\n",
    "convert_mp4_to_wav(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio cleaned and saved as: 222_STORY_BOTH2.wav\n"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "import noisereduce as nr\n",
    "\n",
    "def clean_audio(input_path, output_path, prop_decrease=0.9):\n",
    "    # Read the audio file\n",
    "    audio, sample_rate = sf.read(input_path, dtype='float32')\n",
    "\n",
    "    # Perform noise reduction\n",
    "    reduced_noise = nr.reduce_noise(y=audio, sr=sample_rate, prop_decrease=prop_decrease)\n",
    "\n",
    "    # Save the cleaned audio to a new file\n",
    "    sf.write(output_path, reduced_noise, sample_rate)\n",
    "\n",
    "    print(\"Audio cleaned and saved as:\", output_path)\n",
    "\n",
    "input_path = \"222_STORY_BOTH.wav\"\n",
    "output_path = \"222_STORY_BOTH2.wav\"\n",
    "\n",
    "clean_audio(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio converted to stereo and saved as: /media/faisal/RE_AS/REASEARCHASSISTANT/RECORDS/record1/1_STORY_BOTH_stereo.wav\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_to_stereo(input_path, output_path):\n",
    "    # Load the mono audio file\n",
    "    mono_audio = AudioSegment.from_wav(input_path)\n",
    "\n",
    "    # Convert to stereo by duplicating the mono channel\n",
    "    stereo_audio = mono_audio.set_channels(2)\n",
    "\n",
    "    # Export the stereo audio to a new file\n",
    "    stereo_audio.export(output_path, format=\"wav\")\n",
    "\n",
    "    print(\"Audio converted to stereo and saved as:\", output_path)\n",
    "\n",
    "\n",
    "input_path = \"/media/faisal/RE_AS/REASEARCHASSISTANT/RECORDS/record1/1_STORY_BOTH.wav\"\n",
    "output_path = \"/media/faisal/RE_AS/REASEARCHASSISTANT/RECORDS/record1/1_STORY_BOTH_stereo.wav\"\n",
    "convert_to_stereo(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "import os\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "def cut_and_convert_mp4_to_wav(mp4_path, start_time_ms, end_time_ms, out_path):\n",
    "    # Create a VideoFileClip object from the MP4 file\n",
    "    video_clip = VideoFileClip(mp4_path)\n",
    "\n",
    "    # Set the start and end time of the clip (in seconds)\n",
    "    start_time = start_time_ms / 1000\n",
    "    end_time = end_time_ms / 1000\n",
    "\n",
    "    # Extract the subclip from the original video\n",
    "    subclip = video_clip.subclip(start_time, end_time)\n",
    "\n",
    "    # Generate the output file path for the WAV file\n",
    "    wav_path = os.path.splitext(out_path)[0] + \".wav\"\n",
    "\n",
    "    # Write the subclip to the WAV file\n",
    "    subclip.audio.write_audiofile(wav_path, codec='pcm_s16le', bitrate='16k')\n",
    "\n",
    "    # Close the video clip\n",
    "    video_clip.close()\n",
    "\n",
    "    print(f\"MP4 file '{mp4_path}' is cut and converted to WAV successfully.\")\n",
    "    print(f\"WAV file saved at '{wav_path}'.\")\n",
    "\n",
    "def merge_wav_files(file1_path, file2_path, output_path):\n",
    "    # Read the audio data and sample rate from the first WAV file\n",
    "    data1, sample_rate1 = sf.read(file1_path)\n",
    "\n",
    "    # Read the audio data and sample rate from the second WAV file\n",
    "    data2, sample_rate2 = sf.read(file2_path)\n",
    "\n",
    "\n",
    "    # Check if the sample rates of the two files match\n",
    "    if sample_rate1 != sample_rate2:\n",
    "        raise ValueError(\"Sample rates of the WAV files do not match.\")\n",
    "\n",
    "    # Calculate the number of samples for a 5-second break\n",
    "    break_duration = 5  # seconds\n",
    "    break_samples = int(sample_rate1 * break_duration)\n",
    "\n",
    "    # Create a silent break segment\n",
    "    break_segment = np.zeros((break_samples, data1.shape[1]))\n",
    "\n",
    "    # Concatenate the audio data from both files with the break segment in between\n",
    "    merged_data = np.concatenate((data1, break_segment, data2))\n",
    "\n",
    "    # Write the merged audio data to the output WAV file\n",
    "    sf.write(output_path, merged_data, sample_rate1)\n",
    "\n",
    "    print(f\"WAV files merged and saved at '{output_path}'.\")\n",
    "\n",
    "# Example usage\n",
    "mp4_path = \"/media/faisal/RE_AS/REASEARCHASSISTANT/RECORDS/record234/Done234/234_Emotions_both.mp4\"\n",
    "start_time_ms = 0\n",
    "end_time_ms = 100000\n",
    "out_path = \"ww.wav\"\n",
    "\n",
    "cut_and_convert_mp4_to_wav(mp4_path, start_time_ms, end_time_ms, out_path)\n",
    "\n",
    "# Example usage\n",
    "file1_path = \"ww.wav\"\n",
    "file2_path = \"marissa3s.wav\"\n",
    "output_path = \"merged.wav\"\n",
    "\n",
    "merge_wav_files(file1_path, file2_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/faisal/Desktop/animation_example.mp4.\n",
      "MoviePy - Writing audio in animation_exampleTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/faisal/Desktop/animation_example.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/faisal/Desktop/animation_example.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip, concatenate_videoclips, AudioFileClip\n",
    "from moviepy.audio.AudioClip import AudioArrayClip\n",
    "import numpy as np\n",
    "\n",
    "def add_audio_to_mp4(mp4_path, wav_path, output_path, start_time):\n",
    "    # Load the video clip\n",
    "    video = VideoFileClip(mp4_path)\n",
    "\n",
    "    # Load the audio clip\n",
    "    audio = AudioFileClip(wav_path)\n",
    "\n",
    "    # Set the start time of the audio\n",
    "    audio = audio.subclip(start_time)\n",
    "\n",
    "    # Create a silent video clip with the same duration as the audio clip\n",
    "    duration = audio.duration\n",
    "    silent_video = VideoFileClip(mp4_path).subclip(0, duration)\n",
    "\n",
    "    # Replace the audio of the silent video clip with the audio clip\n",
    "    final_video = silent_video.set_audio(audio)\n",
    "\n",
    "    # Write the final video with audio to the output path\n",
    "    final_video.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\")\n",
    "\n",
    "mp4_path = '/home/faisal/Desktop/interview_example1animation2.mp4'\n",
    "wav_path = '/home/faisal/Desktop/interview_example11.wav'\n",
    "output_path = '/home/faisal/Desktop/animation_example.mp4'\n",
    "start_time = 0  # Start time in seconds\n",
    "\n",
    "add_audio_to_mp4(mp4_path, wav_path, output_path, start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def pad_audio(input_path, output_path, padding_duration):\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_file(input_path)\n",
    "\n",
    "    # Calculate the padding duration in milliseconds\n",
    "    padding_duration_ms = padding_duration * 1000\n",
    "\n",
    "    # Pad the audio with silence at the beginning\n",
    "    padded_audio = AudioSegment.silent(duration=padding_duration_ms) + audio\n",
    "\n",
    "    # Export the padded audio to the output path\n",
    "    padded_audio.export(output_path, format='wav')\n",
    "\n",
    "# Usage example\n",
    "input_path = '/home/faisal/Desktop/interview_example1.wav'\n",
    "output_path = '/home/faisal/Desktop/interview_example11.wav'\n",
    "padding_duration = 1.5  # Padding duration in seconds\n",
    "\n",
    "pad_audio(input_path, output_path, padding_duration)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
